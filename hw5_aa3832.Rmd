---
title: "p8105 hw5"
author:  "Alexey Abramov"
date: "11/15/2020"
output: 
  github_document:
    toc: true
---

# Setup

```{r, setup}
library(tidyverse)
library(readr)
library(rvest)
library(plotly)
library(purrr)
library(stringr)
library(broom)
library(patchwork)


knitr::opts_chunk$set(
  fig.width = 6,
  fig.height = 6,
  out.width = "90%"
)

theme_set(
  ggthemes::theme_fivethirtyeight() + theme(legend.position = "bottom")
  )

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.colour = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Loading the data.

```{r}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",)
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

# Problem 1

## Summarizing the data to create two new columns for total murders and unsolved murders.  

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

## Performing a prop.test for one city.  

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>%
    pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% 
    pull(hom_total)) %>% 
  broom::tidy()
```

## Now will iterate to the remaining cities.  

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

## Plotting results

```{r}
homicide_plot = results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  labs(title = "Unsolved Homicides in American Cities")
```

## Problem 1 -  Describing the data

These homicide data are obtained from an investigative report published in the Washington Post on homicides in 50 American cities.  The article focuses on the cities where murders appear to go unsolved. There are a total of `r nrow(homicide_df)` rows in this dataset. From these data and the accompanying plot titled "Unsolved Homicides in American Cities" we can appreciate that the probability of a homicide going unsolved is highest in Chigago, IL with an estimated 0.73 probability of a murder going unsolved.   

# Problem 2

## Importing one data set 

```{r}
data_1 = read_csv("lda_data/con_01.csv")
```

## Iterating to importing the remaining data... 

```{r}
path_df = 
  tibble(
    path = list.files("lda_data")) %>% 
  mutate(
    path = str_c("lda_data/", path))

read_csv(path_df$path[[1]])
```

## Iterating to add the remaining data

```{r}
path_df = 
  tibble(
    path = list.files("lda_data")) %>% 
  mutate(
    path = str_c("lda_data/", path),
    data = map(path_df$path, read_csv))
```

Checking now to see if this works...

```{r}
path_df$data[[1]]
```

Nice, ok yes it does!

## Data wrangling, and tidying 

This involves separating a few variables and selecting columns and then unnesting. Tried to delete with str_sub but kept getting a strange error.  

```{r}
path_df =
  path_df %>% 
  separate(path, into = c("lda_data", "study_arm"), sep = "/") %>% 
  separate(study_arm, into = c("study_arm", "samp"), sep = "_") %>% 
  separate(samp, into = c("subject", "csv", sep = ".")) %>% 
  select(!c(lda_data, csv, .)) %>% 
  mutate(
    subject = as.numeric(subject),
    study_arm = as.factor(study_arm)) %>% 
  group_by(study_arm) %>% 
  unnest(data)
```

Now to create the spaghetti plot, I think we'll have to pivot longer.

```{r}
path_df =
  path_df %>% 
  pivot_longer(week_1:week_8, 
      names_to = "week", 
      values_to = "observation",
      names_prefix = "week_") %>% 
  mutate(
    week = as.numeric(week))
```

And now graph it.

```{r}
path_plot = 
  path_df %>% 
  ggplot(aes(x = week, y = observation, group = subject)) +
    geom_line() + 
    facet_grid(. ~ study_arm) +  
    stat_smooth(aes(group = 1), method = "lm", se = TRUE) +
  labs(
    title = "Observations Over Time")
  
```

## Problem 2 - Describing the Data

This dataset from 20 subjects from two groups, control and experimental, and taken across 8 week timepoints reflects numeric the researcher's observations. From these data, we can appreciate that over the course of 8 weeks, the observations in the experimental arm increased while those in the control arm decreased slightly.  

# Problem 3

## Creating the dataset

```{r}
sim_ttest = function(n, mu = 0, sigma = 5) {
 
  sim_data = tibble(
    x = rnorm(n = 30, mean = mu, sd = sigma),
  )
 
    ttest= t.test(sim_data, mu=0, sd=5)
    ttest[['p.value']]
    ttest[['estimate']]
   
  sim_results = tibble(
     pvalue = ttest[['p.value']],
     estimate = ttest[['estimate']],
     true_mu = mu
  )
}
```

### Trying a 'for loop' here now.

```{r}
output = vector("list", 5000)

for (i in 1:5000) {
  output[[i]] = sim_ttest(30)
}
sim_results = bind_rows(output)
```

## Testing the function and simulating 5000 times

```{r, cache= TRUE}
sim_results_test =
  rerun(5000, sim_ttest(30, 0, 5)) %>%
  bind_rows()
```

## Simulating across multiple means

```{r}
mu_list =
  list(
    "m_0" = 0,
    "m_1" = 1,
    "m_2" = 2,
    "m_3" = 3,
    "m_4" = 4,
    "m_5" = 5,
    "m_6" = 6)

mu_output = vector("list", length = 7)

for (i in 1:7) {
  mu_output[[i]] = rerun(5, sim_ttest(30, mu_list[[i]], 5))
}
```

## Creating the reject and fail to reject columns.

```{r}
p3_plot1_df =
  bind_rows(mu_output) %>% 
  group_by(true_mu) %>% 
  mutate(
    test_outcome = 
      case_when(
        pvalue < .05 ~ "reject",
        pvalue >= .05 ~ "fail"),
    test_outcome = as.factor(test_outcome)) %>% 
  summarize(
    test_total = n(),
    test_rejected = sum(test_outcome == "reject")) %>% 
  mutate(
    power = test_rejected / test_total)
```

## Plots

### Plot 1

```{r}
p3_plot1 = p3_plot1_df %>% 
  ggplot(aes(x = true_mu, y = power)) + 
  geom_point() + 
  geom_line() + 
  labs(
    title = "The Power of Mu",
    tag = "p3_plot1"
  )

p3_plot1

```

#### Plot 1 Discussion

This plot demonstrates in a provided sample with standard deviation, the greater the difference between the means of the null and alternative distributions, the greater the power.  


### Plot 2

Building back the initial data set to return to the estimate and true mu.  

```{r}
p3_plot2_df =
  bind_rows(mu_output) %>% 
  group_by(true_mu) %>% 
  mutate(
    test_outcome = 
      case_when(
        pvalue < .05 ~ "reject",
        pvalue >= .05 ~ "fail"),
    test_outcome = as.factor(test_outcome))
```

Thinking about how to get the mean estimate in each true mu. 
Pivot wider? Helps to see it but I don't think this will work.  

```{r}
p3_wide_df = p3_plot2_df %>% 
  pivot_wider(
    names_from = true_mu,
    values_from = estimate,
    names_prefix = "var")
```

Group_by and then summarize will probably work better here.  

```{r}
p3_plot2a_df = p3_plot2_df %>% 
  group_by(true_mu) %>% 
  summarize(
    mean_estimate = mean(estimate)
  )
```

#### Plot 2A

```{r}
p3_plot2a = 
  p3_plot2a_df %>% 
  ggplot(aes(x = true_mu, y = mean_estimate)) + 
  geom_point() + 
  geom_line() +
  labs(
    title = "All Results: True Mu to Estimate Mu",
    tag = "p3_plot2a"
  )

p3_plot2a
```

#### Plot 2B

```{r}
p3_plot2b_df =
  p3_plot2_df %>% 
  filter(
    test_outcome == "reject") %>% 
  group_by(true_mu) %>% 
  summarize(
    mean_estimate = mean(estimate))

p3_plot2b = 
  p3_plot2b_df %>% 
  ggplot(aes(x = true_mu, y = mean_estimate)) + 
  geom_point() + 
  geom_line() +
  labs(
    title = "Rejected Null:  True Mu to Estimate Mu",
    tag = "p3_plot2b"
  )

p3_plot2b
```

```{r}
p3_plot2a + p3_plot2b
```

## Plot 2A / 2B Discussion

The sample average of μ̂  across tests for which the nullis rejected is not approximately equal to the true mu.  This makes sense because if the mean of the estimates of mu were approximately equal to the true mu, you would fail to reject the null hypothesis.  
